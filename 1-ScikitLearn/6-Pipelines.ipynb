{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/crowdlearning-etic.png\" alt=\"Logo ETIC\" align=\"right\">\n",
    "\n",
    "\n",
    "<h1><font color=\"#004D7F\" size=6>Pipelines</font></h1>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<div style=\"text-align: right\">\n",
    "<font color=\"#004D7F\" size=3>Antonio Jesús Gil</font><br>\n",
    "<font color=\"#004D7F\" size=3>Fundamentos de Machine Learning</font><br>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un Pipeline consiste en una combinación de estimadores que se ejecutan como si fuesen uno. Más concretamente se trata de una secuencia de transformaciones y el último es un estimador de cualquier tipo (transformador, clasificador, etc.).\n",
    "\n",
    "Pipeline se encarga de ir llamando a las funciones `fit` y `transform` de cada uno de los transformadores hasta que llega al último de ellos, siendo la entrada de la función `fit` el resultado del `transform` anterior.\n",
    "\n",
    "Pipeline tendrá aquellas funciones correspondientes a su último estimador, es decir, si al final hay un clasificador, el Pipeline tendrá las funciones `fit`, `predict` y `score`, si es un transformador, `fit` y `transform`.\n",
    "\n",
    "Se trata de una herramienta muy útil que permite reducir el tamaño del código y ayuda a la reproducibilidad de diferentes experimentos.\n",
    "\n",
    "En el primer ejemplo vamos a definir un __pipeline__ con algunas de las clases que hemos utilizado. Para ello vamos a utilizar la base de datos Wisconsin en formato csv vista en el apartado Transformaciones. Las características en `wisconsin_data`, dispone de ciertos valores perdidos, por lo que __no podía ser pasado__ directamente al clasificador. Por eso, vamos a crear un __pipeline__ que primero utilice un `SimpleImputer` y luego llame a `LogisticRegression`.\n",
    "\n",
    "Igual que en todos los casos anteriores, utilizaremos el __pipeline__ con las funciones `fit`, `predict` y `score`, de la misma forma que si se tratase de un clasificador. Para crear un Pipeline se utiliza una lista de tuplas (clave, valor) donde la clave es un string representativo y el valor es el estimador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import pandas as pd\n",
    "wisconsin = pd.read_csv('wisconsin.csv')\n",
    "wisconsin.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo primero es separar los atributos de la clase.\n",
    "wisconsin_data = wisconsin.drop('label',1)\n",
    "wisconsin_target = wisconsin['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wisconsin_data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos un objeto pipeline compuesto de dos objetos estimador: imputer y logisticregression\n",
    "pipe = Pipeline([('preprocesado', SimpleImputer()), ('clasificador', LogisticRegression())])\n",
    "\n",
    "# hacemos fit con wisconsin_data y wisconsin_target\n",
    "pipe.fit(wisconsin_data,wisconsin_target)\n",
    "\n",
    "# obtenemos la tasa de acierto con la función score del pipeline\n",
    "print(\"Tasa de acierto = {0:.2%}\".format(pipe.score(wisconsin_data,wisconsin_target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section42\"></a> \n",
    "### <font color=\"#004D7F\">Propiedades del Pipeline</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es posible acceder a los elementos que componen el Pipeline de dos formas, mediante una lista con `steps`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O mediante un diccionario con `named_steps`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.named_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es posible también acceder a los hiperparametros de los estimadores ya definidos en el pipeline mediante `set_params` indicando en la función el parametro que se desea modificar de la siguiente forma `<clave del estimador>__<hiperparametro>`. Veamos un ejemplo de esto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actualmente la estrategia para rellenar los nan's es 'mean'\n",
    "pipe.set_params(preprocesado__strategy='median')\n",
    "# Y ahora la strategy es la mediana\n",
    "pipe.named_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero no sólo eso, podemos cambiar también un estimador entero gracias a esta función. Esto es especialmente útil cuando tenemos que probar una serie de clasificadores y el preprocesamiento es siempre el mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "pipe.set_params(clasificador=KNeighborsClassifier())\n",
    "pipe.named_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, podemos obtener los parametros aprendidos en las diferentes etapas del Pipeline si accedemos directamente al estimador con `steps` o `named_steps`. Si usamos el Pipeline actual y realizamos `fit`, podemos ver que es lo que aprende la regresión logística a través de los coeficientes (`coef_`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('preprocesado', SimpleImputer()), ('clasificador', LogisticRegression())])\n",
    "\n",
    "pipe.fit(wisconsin_data,wisconsin_target)\n",
    "print(pipe.named_steps['clasificador'].coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto representa los pesos que se han aprendido para las 10 variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
