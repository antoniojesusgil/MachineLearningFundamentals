{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/crowdlearning-etic.png\" alt=\"Logo ETIC\" align=\"right\">\n",
    "\n",
    "\n",
    "<h1><font color=\"#004D7F\" size=6>Rendimiento de Modelos: Curva ROC & AUC </font></h1>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<div style=\"text-align: right\">\n",
    "<font color=\"#004D7F\" size=3>Antonio Jesús Gil</font><br>\n",
    "<font color=\"#004D7F\" size=3>Fundamentos de Machine Learning</font><br>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"#004D7F\">Curva ROC</font>\n",
    "\n",
    "Una __curva ROC__ (curva de característica operativa del recepto) es un gráfico que muestra el rendimiento de un modelo de clasificación en todos los umbrales de clasificación. Esta curva representa dos parámetros:\n",
    "\n",
    "- Tasa de verdaderos positivos\n",
    "- Tasa de falsos positivos\n",
    "\n",
    "__Tasa de verdaderos positivos (TPR)__ es sinónimo de exhaustividad y, se define:\n",
    "\n",
    "<img src=\"../img/tasaVerdPositivos.png\" height=\"200\" width=\"200\">\n",
    "\n",
    "\n",
    "__Tasa de falsos positivos (FPR)__ se define:\n",
    "\n",
    "<img src=\"../img/TasaFalsosPos.png\" height=\"200\" width=\"200\">\n",
    "\n",
    "Una curva ROC representa __TPR__ frente a __FPR__ en diferentes umbrales de clasificación. Reducir el umbral de clasificación clasifica más elementos como positivos, por lo que aumentarán tanto los falsos positivos como los verdaderos positivos.\n",
    "\n",
    "<img src=\"../img/ROC_curve.png\" height=\"400\" width=\"400\">\n",
    "\n",
    "Para calcular los puntos en una curva ROC, podríamos evaluar un modelo de regresión logística muchas veces con diferentes umbrales de clasificación, pero esto es ineficiente. Afortunadamente, existe un algoritmo eficiente basado en ordenamiento que puede brindarnos esta información, denominado __AUC__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"#004D7F\">AUC: Área bajo la curva ROC</font>\n",
    "\n",
    "AUC significa \"área bajo la curva ROC\". Esto significa que el AUC mide toda el área bidimensional por debajo de la curva ROC completa (piensa en un cálculo integral) de (0,0) a (1,1).\n",
    "\n",
    "<img src=\"../img/AUC.png\" height=\"400\" width=\"400\">\n",
    "\n",
    "El AUC proporciona una medición agregada del rendimiento en todos los umbrales de clasificación posibles. Una forma de interpretar el AUC es como la probabilidad de que el modelo clasifique un ejemplo positivo aleatorio más alto que un ejemplo negativo aleatorio. Observa, a modo de ilustración, los siguientes ejemplos, que están ordenados de izquierda a derecha en orden ascendente con respecto a las predicciones de regresión logística:\n",
    "\n",
    "<img src=\"../img/resModeloRLog.png\" height=\"600\" width=\"600\">\n",
    "\n",
    "Figura: Predicciones en orden ascendente con respecto a la clasificación de regresión logística.\n",
    "\n",
    "El AUC representa la probabilidad de que un ejemplo aleatorio positivo (verde) se posicione a la derecha de un ejemplo aleatorio negativo (rojo).\n",
    "\n",
    "El AUC oscila en valor del 0 al 1. Un modelo cuyas predicciones son un 100% incorrectas tiene un AUC de 0.0; otro cuyas predicciones son un 100% correctas tiene un AUC de 1.0.\n",
    "\n",
    "El AUC es conveniente por las dos razones siguientes:\n",
    "\n",
    "- El AUC es __invariable con respecto a la escala__. Mide qué tan bien se clasifican las predicciones, en lugar de sus valores absolutos.\n",
    "\n",
    "- El AUC es __invariable con respecto al umbral de clasificación__. Mide la calidad de las predicciones del modelo, sin tener en cuenta qué umbral de clasificación se elige.\n",
    "\n",
    "Sin embargo, estas dos razones tienen algunas advertencias, que pueden limitar la utilidad del AUC en determinados casos:\n",
    "\n",
    "- __La invariabilidad de escala no siempre es conveniente__. Por ejemplo, en algunas ocasiones, realmente necesitamos resultados de probabilidad bien calibrados, y el AUC no nos indicará eso.\n",
    "\n",
    "- __La invariabilidad del umbral de clasificación no siempre es conveniente__. En los casos en que hay amplias discrepancias en las consecuencias de los falsos negativos frente a los falsos positivos, es posible que sea fundamental minimizar un tipo de error de clasificación. Por ejemplo, al realizar la detección de spam de correo electrónico, es probable que quieras priorizar la minimización de los falsos positivos (aunque eso resulte en un aumento significativo de los falsos negativos). El AUC no es una métrica útil para este tipo de optimización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
