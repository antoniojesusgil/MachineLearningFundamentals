{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section5\"></a>\n",
    "# <font color=\"#004D7F\"> 5. Pipelines</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un Pipeline consiste en una combinación de estimadores que se ejecutan como si fuesen uno. Más concretamente se trata de una secuencia de transformaciones y el último es un estimador de cualquier tipo (transformador, clasificador, etc.).\n",
    "\n",
    "Pipeline se encarga de ir llamando a las funciones `fit` y `transform` de cada uno de los transformadores hasta que llega al último de ellos, siendo la entrada de la función `fit` el resultado del `transform` anterior.\n",
    "\n",
    "Pipeline tendrá aquellas funciones correspondientes a su último estimador, es decir, si al final hay un clasificador, el Pipeline tendrá las funciones `fit`, `predict` y `score`, si es un transformador, `fit` y `transform`.\n",
    "\n",
    "Se trata de una herramienta muy útil que permite reducir el tamaño del código y ayuda a la reproducibilidad de diferentes experimentos.\n",
    "\n",
    "En el primer ejemplo vamos a definir un __pipeline__ con algunas de las clases que hemos utilizado. Vamos a utilizar `wisconsin_data`, que si recordamos, tenía ciertos valores perdidos, por lo que no podía ser pasado directamente al clasificador. Por eso, vamos a crear un __pipeline__ que primero utilice un `Imputer` y luego llame a `LogisticRegression`.\n",
    "\n",
    "Igual que en todos los casos anteriores, utilizaremos el __pipeline__ con las funciones `fit`, `predict` y `score`, de la misma forma que si se tratase de un clasificador. Para crear un Pipeline se utiliza una lista de tuplas (clave, valor) donde la clave es un string representativo y el valor es el estimador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos la clase pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# creamos un objeto pipeline compuesto de dos objetos estimador: imputer y logisticregression\n",
    "pipe = Pipeline([('preprocess1', Imputer()), ('classifier', LogisticRegression())])\n",
    "\n",
    "# hacemos fit con wisconsin_data y wisconsin_target\n",
    "pipe.fit(wisconsin_data,wisconsin_target)\n",
    "\n",
    "# obtenemos la tasa de acierto con la función score del pipeline\n",
    "print(\"tasa de acierto = {0:.2%}\".format(pipe.score(wisconsin_data,wisconsin_target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section42\"></a> \n",
    "### <font color=\"#004D7F\">Propiedades del Pipeline</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es posible acceder a los elementos que componen el Pipeline de dos formas, mediante una lista con `steps`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O mediante un diccionario con `named_steps`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.named_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es posible también acceder a los hiperparametros de los estimadores ya definidos en el pipeline mediante `set_params` indicando en la función el parametro que se desea modificar de la siguiente forma `<clave del estimador>__<hiperparametro>`. Veamos un ejemplo de esto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actualmente la estrategia para rellenar los nan's es 'mean'\n",
    "pipe.set_params(preprocess1__strategy='median')\n",
    "# Y ahora la strategy es la mediana\n",
    "pipe.named_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero no sólo eso, podemos cambiar también un estimador entero gracias a esta función. Esto es especialmente útil cuando tenemos que probar una serie de clasificadores y el preprocesamiento es siempre el mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "pipe.set_params(classifier=KNeighborsClassifier())\n",
    "pipe.named_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, podemos obtener los parametros aprendidos en las diferentes etapas del Pipeline si accedemos directamente al estimador con `steps` o `named_steps`. Si usamos el Pipeline actual y realizamos `fit`, podemos ver que es lo que aprende la regresión logística a través de los coeficientes (`coef_`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('preprocess1', Imputer()), ('classifier', LogisticRegression())])\n",
    "\n",
    "pipe.fit(wisconsin_data,wisconsin_target)\n",
    "print(pipe.named_steps['classifier'].coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto representa los pesos que se han aprendido para las 10 variables.\n",
    "\n",
    "También podemos observar los coeficientes de la base de datos MNIST, que son mucho más curiosos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(tol = 0.1)\n",
    "\n",
    "lr.fit (mnist_data,mnist_target)\n",
    "\n",
    "show_digits_from_data(lr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En las imágenes anteriores podemos ver una representación de los coeficientes aprendidos para cada dígito. Los puntos más blancos representan un peso positivo, es decir, si hay un atributo (pixel) con un valor blanco (255) en una zona blanca (o gris claro) de los coeficientes aumenta la probabilidad de que la imagen corresponda con ese dígito. Y si una imagen tiene un pixel blanco en una zona negra de los coeficientes disminuye la probabilidad de que esa imagen tenga dibujado el dígito.\n",
    "\n",
    "En algunos casos como el 0, se ve claramente la forma y otros como el 6 no está tan claro, aunque se puede observar una forma de caracola. Sin embargo, hay casos como el 4 o el 9 que es prácticamente inidentificable la forma.\n",
    "\n",
    "### <font color=\"#004D7F\"> <i class=\"fa fa-pencil-square-o\" aria-hidden=\"true\" style=\"color:#113D68\"></i> Ejercicio 6: Pipelines</font>\n",
    "\n",
    "Para terminar se pide que se utilicen unos cuantos Pipelines con los algoritmos que se han visto en esta práctica y las distinas bases de datos. Se obtengan también el rendimiento con las tasas de acierto con `score` y se observe algún que otro parámetro de los aprendidos como puede ser los `coef_`, `get_feature_names()`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
