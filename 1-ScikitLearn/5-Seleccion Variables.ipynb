{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/crowdlearning-etic.png\" alt=\"Logo ETIC\" align=\"right\">\n",
    "\n",
    "\n",
    "<h1><font color=\"#004D7F\" size=6>Selección de Variables</font></h1>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<div style=\"text-align: right\">\n",
    "<font color=\"#004D7F\" size=3>Antonio Jesús Gil</font><br>\n",
    "<font color=\"#004D7F\" size=3>Fundamentos de Machine Learning</font><br>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"#004D7F\">Filter</font> \n",
    "\n",
    "Son métricas univariadas para problemas de clasificación\n",
    "\n",
    "> Test paramétrico __ANOVA__, tiene como hipótesis nula el que, para cada posible valor de la clase, la media de una variable no varía. Solo captura relaciones lineales\n",
    "\n",
    "> __MI__, Mutual Information, captura cualquier tipo de relación\n",
    "\n",
    "Cuanto mayor es el valor de la métrica, más relacion del atributo con la clase. Un valor 0 significa independencia total entre variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#004D7F\"> Ranking por test ANOVA</font> \n",
    "\n",
    "Selecciona las K mejores variables con __SelectKBest__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "datos = sklearn.datasets.load_breast_cancer()\n",
    "X = datos.data\n",
    "Y = datos.target\n",
    "# Añadimos 100 variables con ruido despues de las 30 originales \n",
    "# No deberian ser seleccionadas\n",
    "semilla = 0\n",
    "random = np.random.RandomState(semilla)\n",
    "ruido = random.normal(size=(len(X), 100))\n",
    "X_ruido = np.hstack([X, ruido])\n",
    "X_t, X_T, Y_t, Y_T = train_test_split(X_ruido,Y,test_size=0.2, random_state=semilla)\n",
    "\n",
    "# Seleccionar las 10 mejores segun test ANOVA\n",
    "K = 10\n",
    "ranking = SelectKBest(score_func = f_classif, k=K)\n",
    "ranking.fit(X_t,Y_t)\n",
    "X_t_proyec = ranking.transform(X_t)\n",
    "\n",
    "# Ver ranking visual y de variables seleccionadas \n",
    "print(\"Ranking: {}\".format(np.argsort(ranking.scores_)[::-1][:K]))\n",
    "seleccionados = ranking.get_support()\n",
    "plt.matshow(seleccionados.reshape(1,-1), cmap='prism')\n",
    "plt.xlabel(\"Indice de la variable\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#004D7F\"> Ranking por test ANOVA</font> \n",
    "\n",
    "Porcentaje de variables seleccionadas utilizando __SelectPercentile__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "seleccion = SelectPercentile(f_classif)\n",
    "pipe = Pipeline([('seleccion', seleccion), ('lr', LogisticRegression())])\n",
    "\n",
    "score_means = list()\n",
    "score_stds = list()\n",
    "porcentajes = [1,5] + list(np.linspace(10,100,10))\n",
    "\n",
    "for p in porcentajes:\n",
    "    pipe.set_params(seleccion__percentile=p)\n",
    "    this_scores = cross_val_score(pipe, X, Y)\n",
    "    score_means.append(this_scores.mean())\n",
    "    score_stds.append(this_scores.std())\n",
    "    \n",
    "plt.errorbar(porcentajes, score_means, np.array(score_stds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <font color=\"#004D7F\"> Evaluación de métodos de selección</font> \n",
    "\n",
    "Este ejemplo obtiene una evaluación de la Regresión logística utilizando tanto el método __ANOVA__ como __MI__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "# Seleccionar las 10 mejores segun test ANOVA\n",
    "K = 10\n",
    "ranking_F = SelectKBest(score_func = f_classif, k=K)\n",
    "ranking_F.fit(X_t,Y_t)\n",
    "X_seleccionF = ranking_F.transform(X_t)\n",
    "\n",
    "# Seleccionar las 10 mejores por MI\n",
    "K = 10\n",
    "ranking_MI = SelectKBest(score_func = mutual_info_classif, k=K)\n",
    "ranking_MI.fit(X_t,Y_t)\n",
    "X_seleccionMI = ranking_MI.transform(X_t) # proyectar\n",
    "\n",
    "# crear modelos\n",
    "lr = LogisticRegression(); lr_F = LogisticRegression(); lr_MI = LogisticRegression();\n",
    "lr.fit(X_t,Y_t); lr_F.fit(X_seleccionF,Y_t); lr_MI.fit(X_seleccionMI, Y_t)\n",
    "\n",
    "# Proyectar test y validar modelos\n",
    "XT_F =  ranking_F.transform(X_T); XT_MI = ranking_MI.transform(X_T)\n",
    "score = lr.score(X_T, Y_T)\n",
    "scoreF = lr_F.score(XT_F, Y_T)\n",
    "scoreMI = lr_MI.score(XT_MI, Y_T)\n",
    "\n",
    "print('Acc sin seleccion: {:.4f}'.format(score))\n",
    "print('Acc con 10 mejores ANOVA: {:.4f}'.format(scoreF))\n",
    "print('Acc con 10 mejores MI: {:.4f}'.format(scoreMI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
